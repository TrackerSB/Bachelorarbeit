\chapter{LLVM}
\section{History}
\begin{wrapfigure}{l}{.5\textwidth}
    \caption[The logo of LLVM]{The logo of LLVM \cite{llvmLogo}}
    \includegraphics[width=.5\textwidth]{gfx/llvmLogo.png}
\end{wrapfigure}
\llvm is a collection of modular and reusable compiler and toolchain technologies to support static and dynamic compilation as well as transparent and lifelong program analysis and transformations of arbitrary programs. \cite{LLVMWebsite, LLVMResearchBeginning}\\
Former \llvm has been a reasearch project at the university of Illinois, which was first described in a publication in 2004.
The project has grown so popular that in 2014 the LLVM Foundation was founded for organizing and maintaining the project. \cite{LLVMFoundation}\\
The main goal of \llvm consists of the creation of a compiler framework in which the optimizations and analysis are independent from the underlying os and the used programming language.
To archive the independency \llvmir was created which is solely used within the pipeline.
\enquote{\llvmir is a strongly typed, \ac{SSA} language that connects to a wide variety of high-level languages.} \cite{PolyhedralEmpiricalStudy}

\section{Pipeline}
The \llvmir, on which the components operate, is generated when entering the pipeline of \llvm (\autoref{fig:llvmPipeline}) by translating the files containing sourcecode written in an arbitrary programming language using a frontend like clang.
When leaving the pipeline files containing the appropriate assembler instructions are created out of the (possibly) newly formed \llvmir by the \generator. \cite{IntroLLVM}
\begin{figure}[!ht]
    \caption{The pipeline of LLVM}
    \label{fig:llvmPipeline}
    \centering
    \begin{tikzpicture}
        \node(languages)[nonLlvmIrNode]{C/C++/Obj-C};
        \node(clang)[nonLlvmIrNode, right=of languages]{clang frontend};
        \node(opt)[llvmIrNode, right=of clang]{\opt};
        \node(generator)[llvmIrNode, below=of opt]{\generator};
        \node(linker)[nonLlvmIrNode, left=of generator]{\linker};
        \path[nonLlvmIrPath] (languages) to (clang);
        \path[llvmIrPath] (clang) to (opt);
        \path[llvmIrPath] (opt) -| ($(opt.north east) + (0.5,0.5)$) -| node[auto]{Pass} (opt);
        \path[llvmIrPath] (opt) to (generator);
        \path[nonLlvmIrPath] (generator) to (linker);
    \end{tikzpicture}
    \legend
\end{figure}\\
\subsection{clang frontend}\label{subsec:clangfrontend}
So the first step at the beginning of the pipeline is translating the files containing sourcecode by a front end like the clang frontend -- currently at least C, C++ and other C based languages are supported.
This is done by adding the option \texttt{-emit-llvm} in order \enquote{to abstract away from the specifics} \cite{FastScopDetection} of a programming language.
The option \texttt{-S} may also be passed to generate a human readable textfile instead of a \llvmir binary.
\subsection{LLVM Optimizer}\label{subsec:optimizer}
On these files the the \opt can perform steps for optimizing and analysing the code.
These steps are called \enquote{Passes}.
Such passes can be explicitly invoked by appending the appropriate options to the command \texttt{opt} of the the \opt.
It is also possible to add further custom options by loading (multiple) libraries using the flag \texttt{-load}.
When calling the the \opt the option \texttt{-S} may also be specified for generating a human readable textfile like in \autoref{subsec:clangfrontend}.\\
\subsection{LLVM Code Generator}
When all desired passes are performed the \generator translates \llvmir into assembler.
\subsection{LLVM Linker}
The \linker finally compiles an executable binary.
\subsection{Control Flow Graph (CFG)}
\begin{wrapfigure}{l}{.3\textwidth}
    \caption{The CFG of \autoref{lst:matmulll}}
    \label{fig:exampleCfg}
    \includegraphics[height=12cm]{gfx/matmulCfg.png}
\end{wrapfigure}
At any point the current \cfg of a \llvmir file can be visualized (like \autoref{fig:exampleCfg}) by passing one of the options \texttt{-view-cfg} or \texttt{-view-cfg-only} to the the \opt.
The \cfg is used by many analysis and optimization passes for determining which optimizations can or should be applied.
