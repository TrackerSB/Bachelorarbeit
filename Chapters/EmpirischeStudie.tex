\chapter{Experiment Setup And Execution}
\draftnote{
    Suggested structure by paper:
    \begin{itemize}
        \item Goals: refine research objective
        \item Experimental Units:
            \begin{itemize}
                \item sampling strategy
                \item selected population from which the sample is drawn
                \item planned sample size
                \item instanciation of the sampleing strategy
                \item resulting samples
                \item measures for randomization
                \item characteriztics ("restrictions to the sample")
            \end{itemize}
        \item Experimental Material: objects used in the experiment
        \item Tasks:
            \begin{itemize}
                \item performed by subjects
                \item different groups treated differently?
            \end{itemize}
        \item Hypotheses, Parameters and Variables
        \item Experiment Design?!
        \item Procedure (Subsec: Analysis procedure)?!
        \item Deviations
    \end{itemize}
}
\section{Goals}
As already mentioned this study is investigating the ratio of the part which already can be automatically optimized by Polly, the impact of various reasons for these parts not beeing even larger and the impact the ratio if these reasons could be eliminated.

\section{Measurement Methology}
\draftnote{What is measured?
    \begin{itemize}
        \item ratio sequential and parallel instructions
        \item reasons for parents of SCoPs being invalid as SCoP
        \item Theoretical impact if certain reasons would not appear
    \end{itemize}
}
For measuring, analysis and evaluation of the results the following definitions are introduced.
\subsection{Definition ratios}
Let \(T_i\in\mathbb{N}\) be the execution time of all instructions within all \scops of a project and \(T\in\mathbb{N}\) the overall exeuction time of that project.
Then the ratio of paralizable regions \(R\in\mathbb{Q}\) is defined as:
\[R := \frac{T_i}{T}\]

\subsection[Amdahl's Law]{Amdahl's Law \cite{AmdahlsLaw}}
Let \(N\in\mathbb{N}\) be the number of processors and \(R\in\mathbb{Q}\) be the ratio of paralizable regions.
Then the speedup \(S\in\mathbb{Q}\) is defined as:
\[S := \frac{N}{(1-R)*N+R}\]
\subsection{Reasons for SCoPs being invalid}
These are the critieria implemented by Polly for rejecting a parent of a \scop being also a \scop.
\begin{itemize}
    \item Parent is toplevel (\autoref{lst:parentIsToplevel})
    \item Unsupported terminator instruction
    \item Unreachable in exit block (\autoref{lst:unreachableExitBlock})
    \item Irreducible loops (\autoref{lst:irreducibleLoops})
    \item Undefinded branch condition
    \item Non-integer branch condition
    \item Undefined operands in comparison
    \item Non-affine branch condition
    \item No base pointer
    \item Undefinded base pointer
    \item Variant base pointer (\autoref{lst:variantBasePointer})
    \item Non-affine memory accesses (\autoref{lst:nonAffineMemoryAccesses})
    \item Accesses with differing sizes
    \item Uncomputable loop bounds (\autoref{lst:uncomputeableLoopBounds})
    \item Loop without exit (\autoref{lst:loopWithoutExit})
    \item Function call with side effects (\autoref{lst:functionCallSideEffects})
    \item Complicated access semantics (volatile or atomic)
    \item Base address aliasing (\autoref{lst:baseAddressAliasing})
    \item Integer to pointer conversion (\autoref{lst:integerToPointer})
    \item Stack allocations
    \item Unknown instructions
    \item Contains entry block
    \item Assumed to be unprofitable (\autoref{lst:assumedUnprofitable})
\end{itemize}

\begin{comment}
    Following is copy\&pasted from pollys ScopDetectionDiagnostic.cpp

SCOP_STAT(CFG, ""),
SCOP_STAT(InvalidTerminator, "Unsupported terminator instruction"),
SCOP_STAT(UnreachableInExit, "Unreachable in exit block"),
SCOP_STAT(IrreducibleRegion, "Irreducible loops"),
SCOP_STAT(LastCFG, ""),
SCOP_STAT(AffFunc, ""),
SCOP_STAT(UndefCond, "Undefined branch condition"),
SCOP_STAT(InvalidCond, "Non-integer branch condition"),
SCOP_STAT(UndefOperand, "Undefined operands in comparison"),
SCOP_STAT(NonAffBranch, "Non-affine branch condition"),
SCOP_STAT(NoBasePtr, "No base pointer"),
SCOP_STAT(UndefBasePtr, "Undefined base pointer"),
SCOP_STAT(VariantBasePtr, "Variant base pointer"),
SCOP_STAT(NonAffineAccess, "Non-affine memory accesses"),
SCOP_STAT(DifferentElementSize, "Accesses with differing sizes"),
SCOP_STAT(LastAffFunc, ""),
SCOP_STAT(LoopBound, "Uncomputable loop bounds"),
SCOP_STAT(LoopHasNoExit, "Loop without exit"),
SCOP_STAT(FuncCall, "Function call with side effects"),
SCOP_STAT(NonSimpleMemoryAccess,
          "Compilated access semantics (volatile or atomic)"),
SCOP_STAT(Alias, "Base address aliasing"),
SCOP_STAT(Other, ""),
SCOP_STAT(IntToPtr, "Integer to pointer conversions"),
SCOP_STAT(Alloca, "Stack allocations"),
SCOP_STAT(UnknownInst, "Unknown Instructions"),
SCOP_STAT(Entry, "Contains entry block"),
SCOP_STAT(Unprofitable, "Assumed to be unprofitable"),
SCOP_STAT(LastOther, "")
\end{comment}

\section{Experiment Variables}
The experment variables are listed in \autoref{tab:experimentVariables}.
\draftnote{Which variable is dependant from who?}
\(T_s\) and \(T_p\) are considered as dependant.
Both vary depending on the overall execution time \(T\).\\
Also \(R_s\) and \(R_p\) are dependant as result of their calculation out of \(T_s\) and \(T_p\).\\
Further \(S_s\) and \(S_p\) are calculated out of \(T_s\) and \(T_p\).
So these are also dependant.
\begin{table}[H]
    \myfloatalign
    \begin{tabularx}{\textwidth}{Xccccc} \toprule
        \tableheadline{Name} & \tableheadline{Abbr.} & \tableheadline{Type} & \tableheadline{Scale Type} & \tableheadline{Unit} & \tableheadline{Range} \\ \midrule
        Overall execution time                   & \(T\)   & Indep. & Ratio & \(\mu s\) & \(\mathbb{Q}^+\)\\
        Classification                           & \(C\)   & Indep. & ?     & ? & Text\\
        \midrule
        Program inputs                           & \(P\)   & Con.   & ?     & ? & ?\\
        Test inputs                              & \(TI\)  & Con.   & ?     & ? & ?\\
        \midrule
        Execution time of \scops                 & \(T_s\) & Dep.   & Ratio & \(\mu s\) & \(\mathbb{Q}^+\)\\
        Execution time of parents                & \(T_p\) & Dep.   & Ratio & \(\mu s\) & \(\mathbb{Q}^+\)\\
        Ratio of \scops                          & \(R_s\) & Dep.   & Ratio & Nominal & \([0; 1[ \in \mathbb{Q}\)\\
        Ratio of parents                         & \(R_p\) & Dep.   & Ratio & Nominal & \([0; 1[ \in \mathbb{Q}\)\\
        Theoretical speedup of \scops            & \(S_s\) & Dep.   & Ratio & Nominal & \(\mathbb{Q}\)\\
        Theoretical speedup of parents           & \(S_p\) & Dep.   & Ratio & Nominal & \(\mathbb{Q}\)\\
        \bottomrule
    \end{tabularx}
    \caption[Experiment Variables]{Experiment Variables (Dep.=Dependant; Indep.=Independant; Con.=Controlled)}
    \label{tab:experimentVariables}
\end{table}

\section{Hypotheses}
\draftnote{Already a lot of research is done in the field of polyhedral compilation.}\\
\(H_1\): The main reason for rejecting a \scop should be that its parent already is a toplevel region.\\
\(H_2\): As result the \scops should have quite the maximum size, which is limited due to the fact that toplevel regions can not be classified as \scops by Polly per default.
So the ratio \(R_s\) is expected to be high but significally lower than \(R_p\).
This means that in practice some program can not be optimized by Polly considering every instruction.\\
\(H_3\): The theoretical speedup \(S_s\) is also going to be high but significally lower than \(S_p\) which represents the speedup when every parent of any \scop could also be optimized by Polly.
This is because there are reasons for regions not being a valid \scop which can also be reasons for a program being slow.
In these situations the impact would be really crucial.
\draftnote{
    \begin{itemize}
        \item What's the problem?
        \item What is expected?
        \item research questions?
            \begin{itemize}
                \item Is it relevant in practice?
                \item When is it relevant?
            \end{itemize}
    \end{itemize}
}

\section{Subject Programs}
To target as much as possible real world optimization problems programs are measured which are well known and often used by the community.
The selection of programs is limited due the list of programs available using benchbuild.
\begin{table}[H]
    \resizebox{!}{\textwidth}{
        \begin{minipage}{\textwidth}
            \myfloatalign
            \begin{tabularx}{\textwidth}{lcC} \toprule
                \tableheadline{Name} & \tableheadline{Version} & \tableheadline{Tested Inputs}\\
                \midrule
                \draftnote{\textbf{Used software}}\\
                benchbuild & \draftnote{git} & ---\\
                llvm & \draftnote{git} & ---\\
                clang & \draftnote{git} & ---\\
                polly & \draftnote{git} & ---\\
                polli & \draftnote{git} & ---\\
                \midrule
                \textbf{Benchmarks}\\
                MultiSourceApplications & - & SPEC2006 input data (set:ref)\\
                MultiSourceBenchmarks & - & SPEC2006 input data (set:ref)\\
                SingleSourceBenchmarks & - & SPEC2006 input data (set:ref)\\
                SPEC2006 & - & SPEC2006 input data (set:ref)\\
                Povray & - & SPEC2006 input data (set:ref)\\
                \midrule
                \textbf{Compression}\\
                7z & 9.38.1 & SPEC2006 input data (set:ref)\\
                bzip2 & 1.0.6 & SPEC2006 input data (set:ref)\\
                gzip & 1.6 & SPEC2006 input data (set:ref)\\
                xz & 5.2.1 & SPEC2006 input data (set:ref)\\
                \midrule
                \textbf{Database}\\
                Leveldb & \draftnote{git} & Integrated benchmark\\
                PostgreSQL & & Integrated benchmark\\
                SQLite3 & \draftnote{3080900} & leveldb's integrated benchmark\\
                \midrule
                \textbf{Encryption}\\
                ccrypt & 1.10 & Integrated tests\\
                libressl & 2.1.6\\
                \midrule
                \textbf{Multimedia}\\
                ffmpeg & 3.1.3\\
                povRAY & \draftnote{git} & Integrated sample scenes\\
                x264 & \draftnote{git} & Integrated benchmark\\
                \midrule
                \textbf{Scientific}\\
                LAMMPS & \draftnote{git} & Integrated sample problems\\
                LAPACK & & Integrated tests\\
                LINPACK & & Integrated benchmark\\
                \midrule
                \textbf{Simulation}\\
                crafty & 25.2 & Integrated benchmark\\
                lulesh & 1.0 & Integrated benchmark\\
                lulesh-omp & 1.0 & Integrated benchmark\\
                \midrule
                \textbf{Verification}\\
                minisat & \draftnote{git} & SAT-Race 2008 (reduced)\\
                \midrule
                \textbf{Other}\\
                js\\
                openblas & \draftnote{git}\\
                Rasdaman & \draftnote{git}\\
                \bottomrule
            \end{tabularx}
            \caption[Subject programs]{Subject programs and benchbuild used. (Versions in parenthesis represent git hashes)}
            \label{tab:subjectPrograms}
        \end{minipage}
    }
\end{table}

\section{Tasks}
The first step is creating a new so called experiment for benchbuild\footnote{Benchbuild is a tool for automating the process of downloading, building, applying an experiment at compile time and executing a project on a SLURM Cluster.}.
This experiment is calling the actual pass of Polly for instrumenting a project by specifying the appropriate clang options using \texttt{-Xclang}, collects the generated data and persists it.\\
The pass itself is a FunctionPass.
Thus it is processing every function of the program
In this case the pass is called twice.
Once for instrumenting the actual \scops within, which also includes that ones classified by Polly as \enquote{unprofitable}, and once for instrumenting their parents.
Even the \enquote{unprofitable} \scops are included because they may get profitable to optimize when they are extended to the size of their parents.
To include these \scops the option \texttt{-polly-process-unprofitable} has to be specified using the \texttt{-mllvm} option of clang.
While doing so the informations about why these parents were rejected as \scops are collected.\\
The instrumentation is designed to work for any region (\autoref{subsec:definitionRegion}).
For a given region every incoming edge in the \cfg (\autoref{subsec:cfg}) is bendt to a new node splitting the edges and pointing to the entry of the region.
Within this new node an insruction is placed starting the measurement of the execution time.
This instruction has the same for regions unique id and remembers the system date at the point where it was called.
The same way every outgoing edges in the \cfg of this region are also split introducing a further new node in which an instruction is placed for stopping the measurement having the same id.
When it is called the current system time is requested again and the difference to the starting call is caluculated providing the duration of the measured region.
The measurement itself is done at run time and is realized using the papi library.
\\\draftnote{
    Is this what to write here?
    \begin{enumerate}
        \item Create Pass (\autoref{subsec:optimizer})
        \begin{itemize}
            \item How does the pass work?
        \end{itemize}
        \item Run benchbuild over the group \enquote{benchbuild}
        \item Analyse output
            \begin{itemize}
                \item Most common reasons for rejection?
                \item Ratio of SCoPs?
                \item Possible effect when theoretically solve reasons for rejection?
            \end{itemize}
    \end{enumerate}
}

\section{Design}
Based on the variables in \autoref{tab:experimentVariables} \draftnote{X} experiments are performed.\\
The first experiment is comparing the ratio of \scops \(R_s\) and their parents \(R_p\).\\
In the second experiment the resulting speedups \(S_s\) and \(S_p\) are compared.
\draftnote{
    \begin{itemize}
        \item Which experiments are done?
        \item Multiple program instances?
    \end{itemize}
}

\section{Experiment Setting}
\draftnote{
    \begin{itemize}
        \item Maschine?
        \item Cluster?
        \item LLVM used
        \item LLVM-IR used
        \item How instrumented? (Papi?,...)
        \item Preprations done? (Avoid repeated compilation to LLVM-IR,...)
    \end{itemize}
}
The specifications of the machine used for measurement are listed in \autoref{lst:specifications}.
\begin{code}
    \caption{Specifications of machine used for measurement}
    \inputminted{text}{gfx/chimairaLscpu.log}
    \label{lst:specifications}
\end{code}

\section{Deviations}
The overhead of executing additional instructions for taking measurements is negligable because it is linear to the number of instrumented regions. \draftnote{Really?!}\\
For minimizing the influences to the measurement of the regions itself due the data collected on run time is only written to the database once at the very end of the executed project.\\
Only about 97\% of the measured execution times can be used due to bugs in the implementation which could not be fixed because of time constraints.
The bug is occuring in certain constellations of the basic blocks of a region to measure like the following one which is found in the project \draftnote{projectname}:
\draftnote{Insert example}
To cope with it the appropriate measurements are excluded from the analysis.
\draftnote{Further parents are excluded if there measured children are invalid.}
\draftnote{
    \begin{itemize}
        \item Instabile OS Laufzeit
        \item Messzeit nicht linear zum Input (Messoverhead)
        \item (St√∂reinfluss der Maschine (=Kontrollvariable))
    \end{itemize}
}
