\chapter{Experiment Setup And Execution}
\draftnote{
    Suggested structure by paper:
    \begin{itemize}
        \item Goals: refine research objective
        \item Experimental Units:
            \begin{itemize}
                \item sampling strategy
                \item selected population from which the sample is drawn
                \item planned sample size
                \item instanciation of the sampleing strategy
                \item resulting samples
                \item measures for randomization
                \item characteriztics ("restrictions to the sample")
            \end{itemize}
        \item Experimental Material: objects used in the experiment
        \item Tasks:
            \begin{itemize}
                \item performed by subjects
                \item different groups treated differently?
            \end{itemize}
        \item Hypotheses, Parameters and Variables
        \item Experiment Design?!
        \item Procedure (Subsec: Analysis procedure)?!
        \item Deviations
    \end{itemize}
}
\section{Goals}
As already mentioned this study is investigating the ratio of the part which already can be automatically optimized by Polly, the impact of various reasons for these parts not beeing even larger and the impact the ratio if these reasons could be eliminated.

\section{Measurement Methology}
For measuring, analysis and evaluation of the results the following definitions are introduced.
\subsection{Definition ratios}
Let \(T_i\in\mathbb{N}\) be the execution time of all instructions within all \scops of a project and \(T\in\mathbb{N}\) the overall exeuction time of that project.
Then the ratio of paralizable regions \(R\in\mathbb{Q}\) is defined as:
\[R := \frac{T_i}{T}\]

\subsection[Amdahl's Law]{Amdahl's Law \cite{AmdahlsLaw}}
Let \(N\in\mathbb{N}\) be the number of processors and \(R\in\mathbb{Q}\) be the ratio of paralizable regions.
Then the speedup \(S\in\mathbb{Q}\) is defined as:
\[S := \frac{N}{(1-R)*N+R}\]
\subsection{Reasons for SCoPs being invalid}
These are the critieria implemented by Polly for rejecting a parent of a \scop being also a \scop.
Some of these criteria are referencing to a \LLVM specific value called \undefv.\cite{llvmUndef}
\begin{itemize}
    \item Parent is toplevel (\autoref{lst:parentIsToplevel})\\
        This is simply when the parent of a \scop is the toplevel region.
        Per default a toplevel region can not be a \scop in Polly.
    \item Unsupported terminator instruction\\
        This is occurring when a flow breaking instruction like \texttt{return}, \texttt{throw} or \texttt{goto} is called within a loop.
    \item Unreachable in exit block (\autoref{lst:unreachableExitBlock})\\
        This is appearing when \texttt{unreachable()} is called.\cite{llvmUnreachable}
    \item Irreducible loops (\autoref{lst:irreducibleLoops})\\
        \Eg a loop is interfering with another loop using labels.
        So that loop can not be changed in general.
    \item Undefinded branch condition\\
        It is occurring whenever within a branch condition the value \undefv is appearing.
    \item Non-integer branch condition\\
        \draftnote{This appears when a call instruction is used in the branch condition.}
    \item Undefined operands in comparison\\
        This one appears when the value \undefv.
    \item Non-affine branch condition\\
        This is raised when a non-affine expression like a call instruction is used.
    \item No base pointer\\
        \draftnote{TODO}
    \item Undefinded base pointer\\
        \draftnote{It is raised when a pointer holds the value \undefv.}
    \item Variant base pointer (\autoref{lst:variantBasePointer})\\
        \draftnote{TODO}
    \item Non-affine memory accesses (\autoref{lst:nonAffineMemoryAccesses})\\
        This is appearing when accessing memory in a non-affine way like using \(i^2\) as access steps.
    \item Accesses with differing sizes\\
        \draftnote{TODO}
    \item Uncomputable loop bounds (\autoref{lst:uncomputeableLoopBounds})\\
        It is occurring when the loop bounds could not be computed \eg when the loop bounds are depending on an input parameter.
    \item Loop without exit (\autoref{lst:loopWithoutExit})\\
        This occurrs when a loop is infinite but can not be thrown away because there are cases when the execution terminates.
    \item Function call with side effects (\autoref{lst:functionCallSideEffects})\\
        This is raised when a function is called which is not guaranteed to have no side effects.
    \item Complicated access semantics (volatile or atomic)\\
        \draftnote{TODO}
    \item Base address aliasing (\autoref{lst:baseAddressAliasing})\\
        \draftnote{This happens when it can not be determined whether two pointer have the same base address.}
    \item Integer to pointer conversion (\autoref{lst:integerToPointer})\\
        This occurs when a regular int is used as pointer somewhere into the memory.
    \item Stack allocations\\
        Stack allocations like using \texttt{alloca} can not be handled.
    \item Unknown instructions\\
        \draftnote{TODO}
    \item Contains entry block\\
        \draftnote{TODO}
    \item Assumed to be unprofitable (\autoref{lst:assumedUnprofitable})\\
        When the region is very small or it is not likely that an optimization improves the exection it is left out.
\end{itemize}

\begin{comment}
    Following is copy\&pasted from pollys ScopDetectionDiagnostic.cpp

SCOP_STAT(CFG, ""),
SCOP_STAT(InvalidTerminator, "Unsupported terminator instruction"),
SCOP_STAT(UnreachableInExit, "Unreachable in exit block"),
SCOP_STAT(IrreducibleRegion, "Irreducible loops"),
SCOP_STAT(LastCFG, ""),
SCOP_STAT(AffFunc, ""),
SCOP_STAT(UndefCond, "Undefined branch condition"),
SCOP_STAT(InvalidCond, "Non-integer branch condition"),
SCOP_STAT(UndefOperand, "Undefined operands in comparison"),
SCOP_STAT(NonAffBranch, "Non-affine branch condition"),
SCOP_STAT(NoBasePtr, "No base pointer"),
SCOP_STAT(UndefBasePtr, "Undefined base pointer"),
SCOP_STAT(VariantBasePtr, "Variant base pointer"),
SCOP_STAT(NonAffineAccess, "Non-affine memory accesses"),
SCOP_STAT(DifferentElementSize, "Accesses with differing sizes"),
SCOP_STAT(LastAffFunc, ""),
SCOP_STAT(LoopBound, "Uncomputable loop bounds"),
SCOP_STAT(LoopHasNoExit, "Loop without exit"),
SCOP_STAT(FuncCall, "Function call with side effects"),
SCOP_STAT(NonSimpleMemoryAccess,
          "Compilated access semantics (volatile or atomic)"),
SCOP_STAT(Alias, "Base address aliasing"),
SCOP_STAT(Other, ""),
SCOP_STAT(IntToPtr, "Integer to pointer conversions"),
SCOP_STAT(Alloca, "Stack allocations"),
SCOP_STAT(UnknownInst, "Unknown Instructions"),
SCOP_STAT(Entry, "Contains entry block"),
SCOP_STAT(Unprofitable, "Assumed to be unprofitable"),
SCOP_STAT(LastOther, "")
\end{comment}

\section{Experiment Variables}
The experment variables are listed in \autoref{tab:experimentVariables}.\\
The classification \(C\) describes two types of regions handled within the study.
The one is \enquote{\scop} like explained in \autoref{subsec:definitionScop}.
The other is \enquote{parent} which is the next bigger region surrounding a \scop.\\
The variables \(DynCov_s\) and \(DynCov_p\) are depending on \(TI\) because the selection of tests to run influences the the regions executed and how often they are executed.
So \(TI\) has to be controlled.
This is done by using on the one hand integrated benchmarks brough by the tested programs and on the other hand using benchmarks which are accepted by the community like SPEC2006. (see \autoref{tab:subjectPrograms})
\begin{table}[H]
    \myfloatalign
    \begin{tabularx}{\textwidth}{Xccccc} \toprule
        \tableheadline{Name}            & \tableheadline{Abbr.} & \tableheadline{Type} & \tableheadline{Scale Type} & \tableheadline{Unit}                          & \tableheadline{Range} \\ \midrule
        Classification                  & \(C\)                 & Indep.               & Nominal                    & \makecell{\{Parent,\\\scop\}}                 & Text\\
        Test inputs                     & \(TI\)                & Con.                 & Nominal                    & \makecell{see\\\autoref{tab:subjectPrograms}} & Text\\
        \midrule
        Ratio of \scops                 & \(DynCov_s\)          & Dep.                 & Ratio                      & \%                                            & \([0; 1[ \in \mathbb{Q}\)\\
        Ratio of parents                & \(DynCov_p\)          & Dep.                 & Ratio                      & \%                                            & \([0; 1[ \in \mathbb{Q}\)\\
        %Theoretical speedup of \scops  & \(S_s\)               & Dep.                 & Ratio                      & \%                                            & \(\mathbb{Q}\)\\
        %Theoretical speedup of parents & \(S_p\)               & Dep.                 & Ratio                      & \%                                            & \(\mathbb{Q}\)\\
        \bottomrule
    \end{tabularx}
    \caption[Experiment Variables]{Experiment Variables (Dep.=Dependant; Indep.=Independant; Con.=Controlled)}
    \label{tab:experimentVariables}
\end{table}

\section{Hypotheses}
\(H_1\): The main reason for rejecting a \scop should be that its parent already is a toplevel region because also all \scops classified as unprofitable by Polly are processed.
So a lot of very small functions may be processed.
Whenever such a function has a \scop it is likely that its parent is already a toplevel region.\\
\(H_2\): The coverage \(DynCov_s\) is expected to be about \hTwoAbout, on average.
Even if there are a lot of \scops which are processed the big \scops and the -- according to the execution time -- big \scops may not be able to be optimized.\\
\(H_3\): It is expected that \(DynCov_p \gg DynCov_s\), on average.
This may be a result of the fact that \(DynCov_p\) ignores whether the reasons of parents being rejected as \scop can be eliminated.\\
\(R_1\): Can the main reasons for rejection a \scop be eliminated?

\section{Subject Programs}
The intention is to measure programs which are well known and often used by the community to get a more realistic picture.
The selection of programs (\autoref{tab:subjectPrograms}) is limited due the list of programs available using benchbuild.
\LTXtable{\textwidth}{tables/subjectPrograms.tex}

\section{Tasks}
To create a setup which targets as much as possible real world scenarios integrated benchmarks of programs or SPEC2006 were used.
Further the \lnt provides a hole ranges of benchmarks of various programs.
These will be annotated like \enquote{\(program_{lnt}\)}.

\section{Design}
Based on the experiment variables (see \autoref{tab:experimentVariables}) three experiments are performed to validate the hypotheses.\\
The first experiment takes the most common reason for rejecting a parent as valid \scop and checks whether it is \enquote{parent is toplevel region}.\\
In the second experiment the average value of \(DynCov_s\) is calculated and checked whether it is near \hTwoAbout.\\
The third experiment \(DynCov_p\) and \(DynCov_s\) are compared to check whether \(DynCov_p \gg DynCov_s\).

\section{Experiment Setting}
This study uses instrumentation to retrieve precise timing informations instead of using frameworks like OProfile \cite{oprofile} or GProf \cite{gprof}.
The measurement is realized using the \papi library \cite{papi}.\\
To take these measurement the following steps are performed:\\
The first step is creating a new so called experiment for benchbuild\footnote{Benchbuild is a tool for automating the process of downloading, building, applying an experiment at compile time and executing a project on a SLURM Cluster.}.
This experiment is calling the actual pass of Polly for instrumenting a project by specifying the appropriate clang options using \texttt{-Xclang}, collects the generated data and persists it.\\
The pass itself is a FunctionPass.
Thus it is processing every function of the program
In this case the pass is called twice.
Once for instrumenting the actual \scops within, which also includes that ones classified by Polly as \enquote{unprofitable}, and once for instrumenting their parents.
Even the \enquote{unprofitable} \scops are included because they may get profitable to optimize when they are extended to the size of their parents.
To include these \scops the option \texttt{-polly-process-unprofitable} has to be specified using the \texttt{-mllvm} option of clang.
While doing so the informations about why these parents were rejected as \scops are collected.\\
The instrumentation is designed to work for any region (\autoref{subsec:definitionRegion}).
For a given region every incoming edge in the \cfg (\autoref{subsec:cfg}) is bendt to a new node splitting the edges and pointing to the entry of the region.
Within this new node an insruction is placed starting the measurement of the execution time.
This instruction has the same for regions unique id and remembers the system date at the point where it was called.
The same way every outgoing edges in the \cfg of this region are also split introducing a further new node in which an instruction is placed for stopping the measurement having the same id.
When it is called the current system time is requested again and the difference to the starting call is caluculated providing the duration of the measured region.\\
The specifications of the machine used for measurement are listed in \autoref{tab:specifications}.
\begin{code}
    \captionsetup{type=table}
    \caption{Specifications of machine used for measurement}
    \inputminted{text}{gfx/chimairaLscpu.log}
    \label{tab:specifications}
\end{code}
The exact versions of the used software components are listed in \autoref{tab:usedSoftware}.
\begin{table}[!h]
    \myfloatalign
    \begin{tabularx}{.5\textwidth}{Xc}
        \tableheadline{Name}&\tableheadline{Version}\\ \toprule
        benchbuild & \draftnote{git}\\
        llvm       & (04facbb8)\\
        clang      & (89be37b)\\
        polly      & (0fd4fea)\\
        polli      & \draftnote{git}\\
        \bottomrule
    \end{tabularx}
    \caption[Software used for measurements]{Software used for measurements. (Versions in parenthesis represent short git hashes)}
    \label{tab:usedSoftware}
\end{table}

\section{Deviations}
The overhead of executing additional instructions for taking measurements is negligable because it takes about \draftnote{0.1 \(\mu s\)} to execute an enter and an exit \draftnote{1000000} times.\\
For minimizing the influences of saving the data collected on run time it is only written to the database once at the very end of the executed project.\\
Only about \draftnote{97\%} of the measured execution times can be used due to bugs in the implementation and the projects measured which could not be fixed because of time constraints.
The bug in the implementation is occuring in certain constellations of the basic blocks of a region to measure like the following one which is found in the project \draftnote{projectname}:
\draftnote{Insert example}
To cope with it measurements of regions which have a bigger duration than the hole execution time of the project are excluded.
Also measurements of ratios are excluded where the ratio is greater than 100\%.
These occurr because the filtering of the obviously bad measurements is not enough to exclude all bad ones.
