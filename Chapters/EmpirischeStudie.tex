\chapter{Experiment Setup And Execution}
\draftnote{
    Suggested structure by paper:
    \begin{itemize}
        \item Goals: refine research objective
        \item Experimental Units:
            \begin{itemize}
                \item sampling strategy
                \item selected population from which the sample is drawn
                \item planned sample size
                \item instanciation of the sampleing strategy
                \item resulting samples
                \item measures for randomization
                \item characteriztics ("restrictions to the sample")
            \end{itemize}
        \item Experimental Material: objects used in the experiment
        \item Tasks:
            \begin{itemize}
                \item performed by subjects
                \item different groups treated differently?
            \end{itemize}
        \item Hypotheses, Parameters and Variables
        \item Experiment Design?!
        \item Procedure (Subsec: Analysis procedure)?!
        \item Deviations
    \end{itemize}
}
\section{Goals}
As already mentioned this study is investigating the ratio of the part which already can be automatically optimized by Polly, the impact of various reasons for these parts not beeing even larger and the impact the ratio if these reasons could be eliminated.

\section{Measurement Methology}
\draftnote{What is measured?
    \begin{itemize}
        \item ratio sequential and parallel instructions
        \item reasons for parents of SCoPs being invalid as SCoP
        \item Theoretical impact if certain reasons would not appear
    \end{itemize}
}
\subsection{Definition ratios}
Let \(T_p\in\mathbb{N}\) be the execution time of all instructions within a \scop and \(T\in\mathbb{N}\) the overall exeuction time.
Then the ratio of paralizable regions \(R_p\in\mathbb{Q}\) is defined as:
\[R_p := \frac{T_p}{T}\]

\subsection[Amdahl's Law]{Amdahl's Law \cite{AmdahlsLaw}}
Let \(N\in\mathbb{N}\) be the number of processors and \(R_p\in\mathbb{Q}\) be the ratio of paralizable regions.
Then the speedup \(S\in\mathbb{Q}\) is defined as:
\[S := \frac{N}{(1-R_p)*N+R_p}\]
\subsection{Reasons for SCoPs being invalid}
These are the implemented criteria of Polly for rejecting a parent of a \scop being also a \scop.
\begin{itemize}
    \item Parent is toplevel (\autoref{lst:parentIsToplevel})
    \item Unsupported terminator instruction
    \item Unreachable in exit block (\autoref{lst:unreachableExitBlock})
    \item Irreducible loops (\autoref{lst:irreducibleLoops})
    \item Undefinded branch condition
    \item Non-integer branch condition
    \item Undefined operands in comparison
    \item Non-affine branch condition
    \item No base pointer
    \item Undefinded base pointer
    \item Variant base pointer (\autoref{lst:variantBasePointer})
    \item Non-affine memory accesses (\autoref{lst:nonAffineMemoryAccesses})
    \item Accesses with differing sizes
    \item Uncomputable loop bounds (\autoref{lst:uncomputeableLoopBounds})
    \item Loop without exit (\autoref{lst:loopWithoutExit})
    \item Function call with side effects (\autoref{lst:functionCallSideEffects})
    \item Complicated access semantics (volatile or atomic)
    \item Base address aliasing (\autoref{lst:baseAddressAliasing})
    \item Integer to pointer conversion (\autoref{lst:integerToPointer})
    \item Stack allocations
    \item Unknown instructions
    \item Contains entry block
    \item Assumed to be unprofitable (\autoref{lst:assumedUnprofitable})
\end{itemize}

\begin{comment}
    Following is copy\&pasted from pollys ScopDetectionDiagnostic.cpp

SCOP_STAT(CFG, ""),
SCOP_STAT(InvalidTerminator, "Unsupported terminator instruction"),
SCOP_STAT(UnreachableInExit, "Unreachable in exit block"),
SCOP_STAT(IrreducibleRegion, "Irreducible loops"),
SCOP_STAT(LastCFG, ""),
SCOP_STAT(AffFunc, ""),
SCOP_STAT(UndefCond, "Undefined branch condition"),
SCOP_STAT(InvalidCond, "Non-integer branch condition"),
SCOP_STAT(UndefOperand, "Undefined operands in comparison"),
SCOP_STAT(NonAffBranch, "Non-affine branch condition"),
SCOP_STAT(NoBasePtr, "No base pointer"),
SCOP_STAT(UndefBasePtr, "Undefined base pointer"),
SCOP_STAT(VariantBasePtr, "Variant base pointer"),
SCOP_STAT(NonAffineAccess, "Non-affine memory accesses"),
SCOP_STAT(DifferentElementSize, "Accesses with differing sizes"),
SCOP_STAT(LastAffFunc, ""),
SCOP_STAT(LoopBound, "Uncomputable loop bounds"),
SCOP_STAT(LoopHasNoExit, "Loop without exit"),
SCOP_STAT(FuncCall, "Function call with side effects"),
SCOP_STAT(NonSimpleMemoryAccess,
          "Compilated access semantics (volatile or atomic)"),
SCOP_STAT(Alias, "Base address aliasing"),
SCOP_STAT(Other, ""),
SCOP_STAT(IntToPtr, "Integer to pointer conversions"),
SCOP_STAT(Alloca, "Stack allocations"),
SCOP_STAT(UnknownInst, "Unknown Instructions"),
SCOP_STAT(Entry, "Contains entry block"),
SCOP_STAT(Unprofitable, "Assumed to be unprofitable"),
SCOP_STAT(LastOther, "")
\end{comment}

\section{Experiment Variables}
The experment variables are listed in \autoref{tab:experimentVariables}.
\draftnote{Which variable is dependant from who?}
\(T_s\) and \(T_p\) are considered as dependant. They vary depending on the overall execution time \(T\).\\
Also \(R_p\) is dependant as result of its calculation out of \(T_s\) and \(T_p\).\\
Further \(S_s\) and \(S_p\) are calculated out of \(T_s\) and \(T_p\).
So these are also dependant.
\begin{table}[H]
    \myfloatalign
    \begin{tabularx}{\textwidth}{Xccccc} \toprule
        \tableheadline{Name} & \tableheadline{Abbr.} & \tableheadline{Type} & \tableheadline{Scale Type} & \tableheadline{Unit} & \tableheadline{Range} \\ \midrule
        Overall execution time                   & \(T\)   & Indep. & Ratio & - & \(\mathbb{Q}\)\\
        Classification                           & \(C\)   & Indep. & ?     & - & -\\
        \midrule
        Program inputs                           & \(P\)   & Con.   & ?     & - & -\\
        Test inputs                              & \(TI\)  & Con.   & ?     & - & -\\
        \midrule
        %Execution time of non-\scops             & \(T_s\) & Dep.   & Ratio & - & \(\mathbb{Q}\)\\
        Execution time of \scops                 & \(T_p\) & Dep.   & Ratio & - & \(\mathbb{Q}\)\\
        Ratio of paralizable regions             & \(R_p\) & Dep.   & Ratio & - & \(\mathbb{Q}\)\\
        Theoretical speedup of \scops            & \(S_s\) & Dep.   & Ratio & - & \(\mathbb{Q}\)\\
        %Theoretical speedup of parents of \scops & \(S_p\) & Dep.   & Ratio & - & \(\mathbb{Q}\)\\
        \bottomrule
    \end{tabularx}
    \caption[Experiment Variables]{Experiment Variables (Dep.=Dependant; Indep.=Independant; Con.=Controlled)}
    \label{tab:experimentVariables}
\end{table}

\section{Hypotheses}
Already a lot of research is done in the field of polyhedral compilation.
As result the \scops should have quite the maximum size, which is limited due to the fact that toplevel regions can never be a \scop within Polly.
So the ratio \(R_p\) is expected to be high but is not going to be very near to 1.
This means that in practice some program can not be optimized by Polly considering every instruction.\\
The theoretical speedups \(S_s\) is also going to be high but significally lower than \(S_p\) which represents the speedup when every parent of any \scop could also be optimized by Polly.
This is because there are reasons for regions not being a valid \scop which can also be reasons for a program being slow.
In these situations the impact would be really crucial.
\draftnote{
    \begin{itemize}
        \item What's the problem?
        \item What is expected?
        \item research questions?
            \begin{itemize}
                \item Is it relevant in practice?
                \item When is it relevant?
            \end{itemize}
    \end{itemize}
}

\section{Subject Programs}
\begin{table}[H]
    \resizebox{!}{\textwidth}{
        \begin{minipage}{\textwidth}
            \myfloatalign
            \begin{tabularx}{\textwidth}{lcC} \toprule
                \tableheadline{Name} & \tableheadline{Version} & \tableheadline{Tested Inputs}\\
                \midrule
                \draftnote{\textbf{Used software}}\\
                benchbuild & \draftnote{git} & ---\\
                llvm & \draftnote{git} & ---\\
                clang & \draftnote{git} & ---\\
                polly & \draftnote{git} & ---\\
                polli & \draftnote{git} & ---\\
                \midrule
                %\textbf{Compilation}\\
                %python & 3.4.3 & Integrated tests\\
                %ruby & 2.2.2 & Integrated tests\\
                %tcc & 0.9.26 & Integrated tests\\
                %\midrule
                \textbf{Compression}\\
                7z & 9.38.1 & SPEC2006 input data (set:ref)\\
                bzip2 & 1.0.6 & SPEC2006 input data (set:ref)\\
                gzip & 1.6 & SPEC2006 input data (set:ref)\\
                xz & 5.2.1 & SPEC2006 input data (set:ref)\\
                \midrule
                \textbf{Database}\\
                Leveldb & \draftnote{git} & Integrated benchmark\\
                PostgreSQL & & Integrated benchmark\\
                SQLite3 & \draftnote{3080900} & leveldb's integrated benchmark\\
                \midrule
                \textbf{Encryption}\\
                ccrypt & 1.10 & Integrated tests\\
                libressl & 2.1.6\\
                %mcrypt & 2.6.8 & Integrated benchmark\\
                \midrule
                \textbf{Multimedia}\\
                ffmpeg & 3.1.3\\
                povRAY & \draftnote{git} & Integrated sample scenes\\
                x264 & \draftnote{git} & Integrated benchmark\\
                \midrule
                \textbf{Scientific}\\
                LAMMPS & \draftnote{git} & Integrated sample problems\\
                LAPACK & & Integrated tests\\
                LINPACK & & Integrated benchmark\\
                \midrule
                \textbf{Simulation}\\
                crafty & 25.2 & Integrated benchmark\\
                lulesh & 1.0 & Integrated benchmark\\
                lulesh-omp & 1.0 & Integrated benchmark\\
                \midrule
                \textbf{Verification}\\
                %crocopat & 2.1.4 & Integrated benchmark\\
                minisat & \draftnote{git} & SAT-Race 2008 (reduced)\\
                \midrule
                \textbf{Other}\\
                js\\
                %openblas & \draftnote{git}\\
                %Rasdaman & \draftnote{git}\\
                %scimark  & \draftnote{git?}\\
                \bottomrule
            \end{tabularx}
            \caption[Subject programs]{Subject programs and benchbuild used. (Versions in parenthesis represent git hashes)}
            \label{tab:subjectPrograms}
        \end{minipage}
    }
\end{table}

\section{Tasks}
The first step is creating a new so called experiment for benchbuild\footnote{Benchbuild is a tool for automating the process of downloading, building, applying an experiment at compile time and executing a project on a SLURM Cluster.}.
This experiment is calling the actual pass of Polly for instrumenting a project by specifying the appropriate clang options using \texttt{-Xclang}, collects the generated data and persists it.\\
The pass itself is a FunctionPass.
Thus it is processing every function of the program
In this case the pass is called twice.
Once for instrumenting the actual \scops within, which also includes that ones classified by Polly as \enquote{unprofitable}, and once for instrumenting their parents.
Even the \enquote{unprofitable} \scops are included because they may get profitable to optimize when they are extended to the size of their parents.
To include these \scops the option \texttt{-polly-process-unprofitable} has to be specified using the \texttt{-mllvm} option of clang.
While doing so the informations about why these parents were rejected as \scops are collected.\\
The instrumentation is working for any region (\autoref{subsec:definitionRegion}).
For a given region every incoming edge in the \cfg (\autoref{subsec:cfg}) a new node splitting the edge and pointing to the entry of the region is introduced.
Within these new nodes insructions are placed starting the measurement of the execution time.
These instructions have the same for regions unique id and remember the system date at the point where they were called.
The same way every outgoing edges in the \cfg of this region are also split introducing further new nodes in which instructions are placed for stopping the measurement having the same id.
When these are called the current system time is requested again and the difference to the starting call is caluculated providing the duration of the measured region.
The measurement itself is done at run time and is realized using the papi library.
\\\draftnote{
    Is this what to write here?
    \begin{enumerate}
        \item Create Pass (\autoref{subsec:optimizer})
        \begin{itemize}
            \item How does the pass work?
        \end{itemize}
        \item Run benchbuild over the group \enquote{benchbuild}
        \item Analyse output
            \begin{itemize}
                \item Most common reasons for rejection?
                \item Ratio of SCoPs?
                \item Possible effect when theoretically solve reasons for rejection?
            \end{itemize}
    \end{enumerate}
}

\section{Design}
\draftnote{
    \begin{itemize}
        \item Which experiments are done?
        \item Multiple program instances?
    \end{itemize}
}

\section{Experiment Setting}
\draftnote{
    \begin{itemize}
        \item Maschine?
        \item Cluster?
        \item LLVM used
        \item LLVM-IR used
        \item How instrumented? (Papi?,...)
        \item Preprations done? (Avoid repeated compilation to LLVM-IR,...)
    \end{itemize}
}

\section{Deviations}
For minimizing the influences to the measurement of the regions due to the instrumentation the data collected on run time is only written to the database once at the very end of the executed project.
\draftnote{
    \begin{itemize}
        \item Instabile OS Laufzeit
        \item Messzeit nicht linear zum Input (Messoverhead)
        \item (St√∂reinfluss der Maschine (=Kontrollvariable))
    \end{itemize}
}
